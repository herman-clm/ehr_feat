{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-produce FEAT results with a logistic regression model\n",
    "\n",
    "- the goal here is to reproduce the FEAT model for resistant hypertension using a logistic regression \n",
    "model from sklearn. that model can then be used to calculate and visualize shap values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load files the same way as Feat runs\n",
    "targets = {\n",
    "            'htn_dx_ia':'Htndx',\n",
    "            'res_htn_dx_ia':'ResHtndx', \n",
    "            'htn_hypok_dx_ia':'HtnHypoKdx', \n",
    "            'HTN_heuristic':'HtnHeuri', \n",
    "            'res_HTN_heuristic':'ResHtnHeuri',\n",
    "            'hypoK_heuristic_v4':'HtnHypoKHeuri'\n",
    "            }\n",
    "    \n",
    "drop_cols = ['UNI_ID'] + list(targets.keys())\n",
    "repeat = 101\n",
    "target = 'res_htn_dx_ia'\n",
    "fold = 'A'\n",
    "random_state = 1318\n",
    "rdir = 'reproduction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from evaluate_model import evaluate_model, read_data\n",
    "from models.Feat_boolean import clf as feat_clf\n",
    "from models.Feat_boolean import name as feat_name\n",
    "\n",
    "X_train, y_train, X_test, y_test = read_data(target, fold, repeat, '../' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_clf, results  = evaluate_model(feat_clf, feat_name,                               \n",
    "               target, fold, random_state, rdir,        \n",
    "               repeat, data_dir='../')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = {}\n",
    "y_pred_test = {}\n",
    "y_predproba_train = {}\n",
    "y_predproba_test = {}\n",
    "y_pred_train['feat'] = feat_clf.predict(X_train)\n",
    "y_predproba_train['feat'] = feat_clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_clf.get_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_clf.get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# LR = LogisticRegressionCV(Cs = np.logspace(-6,3,10),\n",
    "#                            penalty='l2',\n",
    "#                            solver = 'liblinear')\n",
    "LR = LogisticRegression(C=1.0, penalty='l2', intercept_scaling=1.0, solver='liblinear')\n",
    "XT_train = feat_clf.transform(X_train)\n",
    "XT_train_norm = StandardScaler().fit_transform(XT_train)\n",
    "LR.fit(XT_train_norm, y_train)\n",
    "y_pred_train['LR'] = LR.predict(XT_train_norm)\n",
    "y_predproba_train['LR'] = LR.predict_proba(XT_train_norm)\n",
    "#Logistic Regression Model\n",
    "print('LR trained on normalized data')\n",
    "print('beta coeffs')\n",
    "print(LR.coef_)\n",
    "print('offset')\n",
    "print(LR.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.abs(y_pred_train['feat'] - y_pred_train['LR'])))\n",
    "print(np.sum(np.abs(y_predproba_train['feat'] - y_predproba_train['LR'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**conclusion**: These models basically match. There is a very small error in the prediction probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reproduce FEAT's features\n",
    "\n",
    "that way we can store an LR model and run it thru Shap.\n",
    "The model's features output should be checked against feat_clf.transform(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sum_enc_during_htn_meds_3','median_enc_during_htn_meds_4_plus',\n",
    "            'sd_enc_during_htn_meds_2','mean_systolic','max.CALCIUM', \n",
    "            're_htn_spec_sum' ]:\n",
    "    print('location of',col,':',[i for i,c in enumerate(X_train.columns) if c==col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from feat_transformer import FeatTransformer\n",
    "\n",
    "ft_lr_estimator = Pipeline( [\n",
    "    ('prep', FeatTransformer()),\n",
    "    ('est', LogisticRegression(C=1.0, penalty='l2', intercept_scaling=1.0, solver='liblinear'))\n",
    "]\n",
    ")\n",
    "\n",
    "ft_lr_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train['FT_LR'] = ft_lr_estimator.predict(X_train)\n",
    "y_predproba_train['FT_LR'] = ft_lr_estimator.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.abs(y_pred_train['feat'] - y_pred_train['FT_LR'])))\n",
    "print(np.sum(np.abs(y_predproba_train['feat'] - y_predproba_train['FT_LR'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('Feat_reconstruct_{}_{}_{}_{}.pkl'.format(target,fold,repeat,random_state), 'wb') as of:\n",
    "    pickle.dump(ft_lr_estimator, of)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
