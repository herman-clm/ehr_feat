{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates SHAP plots based on the final model fully trained on the training data set. It requires access to Dataset101 folder containing the train/test datasets, as well as the pickled benchmark models.\n",
    "\n",
    "In progress: Use KernelExplainer to generate SHAP plots for the trained FEAT model...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import shap\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#Read test dataset (300 random patients)\n",
    "targets = {\n",
    "            'htn_dx_ia':'Htndx',\n",
    "            'res_htn_dx_ia':'ResHtndx', \n",
    "            'htn_hypok_dx_ia':'HtnHypoKdx', \n",
    "            'HTN_heuristic':'HtnHeuri', \n",
    "            'res_HTN_heuristic':'ResHtnHeuri',\n",
    "            'hypoK_heuristic_v4':'HtnHypoKHeuri'\n",
    "            }\n",
    "rev_targets = {v:k for k,v in targets.items()}\n",
    "nice_targets = {\n",
    "            'Htndx':'HTN',\n",
    "            'ResHtndx':'Resistant HTN', \n",
    "            'HtnHypoKdx':'HTN-Hypokalemia', \n",
    "            'HtnHeuri':'HTN Heuristic', \n",
    "            'ResHtnHeuri':'Resistant HTN Heuristic',\n",
    "            'HtnHypoKHeuri':'HTN-Hypokalemia Heuristic'\n",
    "            }\n",
    "nice_model = {\n",
    "          'LogisticRegression_L1':'LR L1',\n",
    "          'LogisticRegression_L2':'LR L2',\n",
    "          'RandomForest':'RF',\n",
    "          'Feat_reconstruct_linear':'FEAT linear',\n",
    "          'Feat_reconstruct_kernel':'FEAT'\n",
    "}\n",
    "drop_cols = ['UNI_ID'] + list(targets.keys())\n",
    "rdir = 'resultsFinal_r1'\n",
    "\n",
    "#Select 20 random patients\n",
    "#NB: This needs to be fixed to represent more true positive patients.\n",
    "# select = range(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load short feature names\n",
    "class smart_dict(dict):\n",
    "    def __missing__(self, key):\n",
    "#         print(key)\n",
    "        return key\n",
    "    \n",
    "df_names = pd.read_csv('Feat_Variable_Names.csv')\n",
    "print(df_names.columns)\n",
    "feature_nice = smart_dict({row['Variable Name ']:row['Short Name'] for _, row in df_names.iterrows()})\n",
    "print(feature_nice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from feat_transformer import FeatTransformer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_shap_values(model, target, interactions=False):\n",
    "    \"\"\"Makes a shap decision and summary plot for a model and target.\"\"\"\n",
    "    print(model,target)\n",
    "    target_raw = rev_targets[target]\n",
    "    df_train = pd.read_csv(\n",
    "                '../Dataset' + str(101) + '/' + target + '/' + target + 'ATrain.csv')\n",
    "    df_X_train = df_train.drop(drop_cols,axis=1)  \n",
    "    df_test = pd.read_csv(\n",
    "                '../Dataset' + str(101) + '/' + target + '/' + target + 'ATest.csv')\n",
    "    df_X_test = df_test.drop(drop_cols,axis=1)  \n",
    "    df_y_test = df_test[target_raw].values\n",
    "    \n",
    "    if 'Feat' in model:\n",
    "        pickles = ['Feat_reconstruct_res_htn_dx_ia_A_101_1318.pkl']\n",
    "        #TODO: grab column names\n",
    "    else:\n",
    "        pickles = glob('../'+rdir+'/' + target_raw + '/' + model + '/' + '*.pkl')\n",
    "    print(pickles)\n",
    "    assert(len(pickles)==1)\n",
    "    name = pickles[0]\n",
    "    print('loading',name)\n",
    "    m = pickle.load(open(name,'rb'))\n",
    "    feature_names = df_X_train.columns\n",
    "    if model in ['RandomForest','DecisionTree']:\n",
    "        explainer = shap.TreeExplainer(m)\n",
    "        expected_value = explainer.expected_value[1]\n",
    "        features = df_X_test\n",
    "    elif 'Logistic' in model or model == 'Feat_reconstruct_linear': \n",
    "        feature_perturbation = \"correlation_dependent\" if interactions else \"interventional\"\n",
    "        m_prep = m.named_steps['prep']\n",
    "        m_est = m.named_steps['est']\n",
    "        if 'Feat' in model:\n",
    "            feature_names = m_prep.feature_names\n",
    "        print('feature_names:',feature_names)\n",
    "        df_X_train_trans = pd.DataFrame(m_prep.transform(df_X_train), \n",
    "#                                         index=df_X_train.index, \n",
    "                                        columns=feature_names)\n",
    "        df_X_test_trans = pd.DataFrame(m_prep.transform(df_X_test), \n",
    "#                                         index=df_X_test.index, \n",
    "                                       columns=feature_names)\n",
    "        explainer = shap.LinearExplainer(m_est, df_X_train_trans,\n",
    "                                         feature_perturbation=feature_perturbation,\n",
    "                                        )\n",
    "        \n",
    "        expected_value = explainer.expected_value\n",
    "        features = df_X_test_trans\n",
    "    elif model == 'Feat_reconstruct_kernel':\n",
    "        explainer = shap.KernelExplainer(m.predict_proba, shap.kmeans(df_X_test, 10))\n",
    "        features = df_X_test\n",
    "        expected_value = explainer.expected_value[1]\n",
    "        \n",
    "#     expected_value = expected_value[1]\n",
    "    print(f\"Explainer expected value: {expected_value}\")\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        shap_values = explainer.shap_values(features) #[1]\n",
    "    if model in ['RandomForest','DecisionTree', 'Feat_reconstruct_kernel'] :\n",
    "        shap_values = shap_values[1]\n",
    "            \n",
    "    y_pred = m.predict(df_X_test)\n",
    "    y_pred_proba = m.predict_proba(df_X_test)[:,1]\n",
    "#     print('y_pred:',y_pred)\n",
    "\n",
    "    return {\n",
    "        'shap_values':shap_values, \n",
    "        'expected_value':expected_value, \n",
    "        'y_true':df_y_test, \n",
    "        'y_pred':y_pred, \n",
    "        'y_pred_proba':y_pred_proba,\n",
    "        'features':features, \n",
    "        'feature_names':feature_names\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate shap values\n",
    "commented out for now in lieu of loading pickles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "models = [\n",
    "#           'LogisticRegression_L1',\n",
    "#           'LogisticRegression_L2',\n",
    "# #           'RandomForest',\n",
    "          'Feat_reconstruct_linear',\n",
    "          'Feat_reconstruct_kernel'\n",
    "         ]\n",
    "# models = ['Feat_reconstruct']\n",
    "targets = ['ResHtndx']\n",
    "shap_values, expected_value, y_true, y_pred, misclassified, features, feature_names = {},{},{},{},{},{},{} \n",
    "results = {}\n",
    "for model in models:\n",
    "    if model == 'RandomForest' or model == 'Feat_reconstruct_kernel':\n",
    "        interactions = [False]\n",
    "    else:\n",
    "        interactions = [True, False]\n",
    "    for interaction in interactions: \n",
    "        for target in targets:\n",
    "        \n",
    "            idx = (model, target, interaction)\n",
    "            results[idx] = get_shap_values(model, target, interactions=interaction)\n",
    "            \n",
    "            # save shap values data\n",
    "            if not os.path.exists('shap_values/'+rdir):\n",
    "                os.makedirs('shap_values/'+rdir)\n",
    "            with open('shap_values/'+rdir+'-'.join([str(i) for i in idx])+'.pkl', 'wb') as f:\n",
    "                pickle.dump(results[idx],f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from feat_transformer import FeatTransformer\n",
    "\n",
    "%matplotlib inline\n",
    "def select(y_true, y_pred, n_samples):\n",
    "    \"\"\"Return a selection of points to visualize\"\"\"\n",
    "    random_state = 42 # don't touch unless you want to get a new random sample!\n",
    "    np.random.seed(random_state)\n",
    "    misclassified = y_pred != y_true #[select]\n",
    "    print('misclassified samples:',np.sum(misclassified))\n",
    "    rate = np.sum(misclassified)/len(y_pred)\n",
    "    print('misclassification rate:',rate)\n",
    "    # select a subset of samples for decision plot. \n",
    "    # pick n_samples/2 positive cases and n_samples/2 negative cases. \n",
    "    # half of each should be misclassified. \n",
    "    idx = np.arange(len(y_true))\n",
    "    miss_pos = (y_true==1) & misclassified\n",
    "    miss_neg = (y_true==0) & misclassified\n",
    "    hit_pos = (y_true==1) & ~misclassified\n",
    "    hit_neg = (y_true==0) & ~misclassified\n",
    "    hit_pos_samples = np.random.choice(idx[hit_pos], size=math.ceil((1-rate)*n_samples/2))\n",
    "    miss_pos_samples = np.random.choice(idx[miss_pos], size=math.ceil((rate)*n_samples/2))\n",
    "    hit_neg_samples = np.random.choice(idx[hit_neg], size=math.ceil((1-rate)*n_samples/2))\n",
    "    miss_neg_samples = np.random.choice(idx[miss_neg], size=math.ceil(rate*n_samples/2))\n",
    "    print(\n",
    "        'positive hits:',len(hit_pos_samples),\n",
    "        'positive misses:',len(miss_pos_samples),\n",
    "        'negative hits:',len(hit_neg_samples),\n",
    "        'negative misses:',len(miss_neg_samples),\n",
    "         )\n",
    "    select = list(hit_pos_samples) + list(miss_pos_samples) + list(hit_neg_samples) + list(miss_neg_samples)\n",
    "\n",
    "#     print('select:',select)\n",
    "    return select, misclassified\n",
    "    \n",
    "def make_shap_plots(model, target, shap_values, expected_value, select,\n",
    "                    misclassified,  features, feature_names, \n",
    "                    n_features = 20, interactions=False,\n",
    "                    axes=[], axes_labels=['A','B']):\n",
    "    \"\"\"Makes a shap decision and summary plot for a model and target.\"\"\"\n",
    "    print('axes:',axes)\n",
    "    if axes == []:\n",
    "        figsize=(12,6)\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize=figsize)\n",
    "        save = True\n",
    "    else:\n",
    "        ax1 = axes[0]\n",
    "        ax2 = axes[1]\n",
    "        save=False\n",
    "    plt.sca(ax1) \n",
    "    \n",
    "    nice_feature_names = [' > '.join([feature_nice[fn.split('>')[0]]]+fn.split('>')[1:]) \n",
    "                            for fn in feature_names]\n",
    "#     feature_order = feature_order[-min(n_features, len(feature_order)):]\n",
    "        \n",
    "    shap.summary_plot(shap_values, \n",
    "                      features=features, \n",
    "                      feature_names=nice_feature_names,\n",
    "                      show=False,\n",
    "#                       cmap='viridis',\n",
    "                      max_display=n_features,\n",
    "                      sort=True\n",
    "                     )\n",
    "#     plt.gca().set_title(model+' model of ' + target)\n",
    "#     plt.gcf().set_size_inches(figsize)\n",
    "    ax1.text(-1,1.0,axes_labels[0],\n",
    "             color='k',fontsize=24, \n",
    "             transform=ax1.transAxes )\n",
    "    print('shap select;',shap_values[select].shape)\n",
    "    print('features select;',features.loc[select,:].shape)\n",
    "    plt.sca(ax2) \n",
    "    if 'linear' in model.lower() or 'logistic' in model.lower():\n",
    "        link='logit'\n",
    "    else:\n",
    "        link='identity'\n",
    "    print('link:',link)\n",
    "    feature_order = np.argsort(np.sum(np.abs(shap_values), axis=0))\n",
    "    \n",
    "    shap.decision_plot(expected_value, shap_values[select], features.loc[select,:].reset_index(), \n",
    "                       feature_names=nice_feature_names,\n",
    "                       feature_display_range=slice(None, -(n_features+1), -1),\n",
    "                       ignore_warnings=True,\n",
    "                       highlight=misclassified[select],\n",
    "                       show=False,\n",
    "                       plot_color='viridis',\n",
    "                       link=link,\n",
    "                       feature_order = feature_order\n",
    "                      )\n",
    "    plt.plot([0.5, 0.5],[0,n_features],':k', alpha=0.3)\n",
    "    ax2.text(-0.2,1.0, axes_labels[1], \n",
    "             color='k', fontsize=24, \n",
    "             transform=ax2.transAxes)\n",
    "#     ax2.XTick.remove()\n",
    "    ax2.set_yticklabels([])\n",
    "#     if 'randomforest' in model.lower():\n",
    "#         ax2.set_xlim((0,1))\n",
    "#     ax2.colorbar()\n",
    "    \n",
    "    if 'feat' in model.lower(): \n",
    "        model_name = 'FEAT'\n",
    "    else:\n",
    "        model_name = model \n",
    "        \n",
    "#     plt.gca().set_title(model+' model of ' + target)\n",
    "\n",
    "#     #Just highlight #11 (misclassified patient)\n",
    "#     shap.decision_plot(expected_value, shap_values[11], \n",
    "#                        feature_names=features.columns,\n",
    "#                        features.iloc[11], feature_display_range=slice(None, -21, -1),\n",
    "#                        ignore_warnings=True, highlight=0)\n",
    "\n",
    "    if save:\n",
    "        fig.suptitle(nice_model[model]+' model of ' + target)\n",
    "        fig.set_size_inches(figsize)\n",
    "        plt.tight_layout()\n",
    "        name = 'shap_'+target+'_'+model\n",
    "        if interactions and model != 'RandomForest':\n",
    "            name = name + '_interactions'\n",
    "        if not os.path.exists('figs/'+rdir):\n",
    "            os.mkdir('figs/'+rdir)\n",
    "        for filetype in ['.pdf','.png','.svg']:\n",
    "            plt.savefig('figs/'+rdir+'/'+name+filetype, dpi=400)\n",
    "    else:\n",
    "        plt.suptitle(nice_model[model]+' model of ' + target)\n",
    "        return ax1, ax2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_ids(model, target, selected, misclassified):\n",
    "    target_raw = rev_targets[target]\n",
    "    df_test = pd.read_csv(\n",
    "                '../Dataset' + str(101) + '/' + target + '/' + target + 'ATest.csv')\n",
    "    patient_ids = df_test['UNI_ID'].values\n",
    "\n",
    "    df_X_test = df_test.drop(drop_cols,axis=1)  \n",
    "    df_y_test = df_test[target_raw].values\n",
    "   \n",
    "    if 'Feat' in model:\n",
    "        pickles = ['Feat_reconstruct_res_htn_dx_ia_A_101_1318.pkl']\n",
    "        #TODO: grab column names\n",
    "    else:\n",
    "        pickles = glob('../'+rdir+'/' + target_raw + '/' + model + '/' + '*.pkl')\n",
    "    print(pickles)\n",
    "    assert(len(pickles)==1)\n",
    "    name = pickles[0]\n",
    "    print('loading',name)\n",
    "    m = pickle.load(open(name,'rb'))\n",
    "    \n",
    "    y_pred = m.predict(df_X_test)\n",
    "    y_pred_proba = m.predict_proba(df_X_test)[:,1]\n",
    "   \n",
    "    selected= np.array(selected)\n",
    "    misclassified = np.array(misclassified)\n",
    "    miss_select = selected[misclassified[selected]] \n",
    "    y_pred_select = y_pred_proba[selected]\n",
    "    y_true_select = df_y_test[selected]\n",
    "    pt_select = patient_ids[selected]\n",
    "    y_pred_miss = y_pred_proba[miss_select]\n",
    "    pt_miss = patient_ids[miss_select]\n",
    "    \n",
    "    idx = np.argsort(y_pred_select)[::-1]\n",
    "    print('shap patient selections for',model,'of',target)\n",
    "    for pt, lab, yp in zip(pt_select[idx], y_true_select[idx], y_pred_select[idx]):\n",
    "        if pt in pt_miss: \n",
    "            print('MISS patient:{}, label:{}, prediction:{}'.format(pt,lab,yp))\n",
    "        else:\n",
    "            print('patient:{}, label:{}, prediction:{}'.format(pt,lab,yp))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['Feat_reconstruct_kernel']\n",
    "# targets = ['ResHtndx']\n",
    "models = [\n",
    "          'LogisticRegression_L1',\n",
    "          'LogisticRegression_L2',\n",
    "          'RandomForest',\n",
    "          'Feat_reconstruct_linear',\n",
    "          'Feat_reconstruct_kernel'\n",
    "         ]\n",
    "targets = ['ResHtndx']\n",
    "n_samples = 20\n",
    "interactions=True\n",
    "for model in models:\n",
    "    n_features = 20 if 'Feat' not in model else 6\n",
    "    if model == 'RandomForest' or model == 'Feat_reconstruct_kernel':\n",
    "        interactions = [False]\n",
    "    else:\n",
    "        interactions = [True, False]\n",
    "    for interaction in interactions:\n",
    "        for target in targets:\n",
    "            idx = (model, target, interaction)\n",
    "            print(idx)\n",
    "            with open('shap_values/'+rdir+'-'.join([str(i) for i in idx])+'.pkl','rb') as f:\n",
    "                results = pickle.load(f)\n",
    "#             print('results:',results)\n",
    "            selected, misclassified =  select(results['y_true'], results['y_pred'], n_samples)\n",
    "            get_ids(model, target, selected, misclassified)\n",
    "            make_shap_plots(model, target, \n",
    "                            results['shap_values'], \n",
    "                            results['expected_value'], \n",
    "                            selected,\n",
    "                            misclassified,\n",
    "                            results['features'], \n",
    "                            results['feature_names'],\n",
    "                            n_features=n_features,\n",
    "                            interactions=interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make combined logistic regression / feat plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          'LogisticRegression_L1',\n",
    "          'Feat_reconstruct_linear'\n",
    "         ]\n",
    "# models = ['Feat_reconstruct']\n",
    "targets = ['ResHtndx']\n",
    "\n",
    "n_samples = 20\n",
    "interactions=True\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,12))\n",
    "print('axes shape:',axes.shape)\n",
    "i=0\n",
    "for model in models:\n",
    "    n_features = 20 if 'Feat' not in model else 6\n",
    "#     interaction = model != 'Feat_reconstruct_kernel'\n",
    "    interaction = False\n",
    "    for target in targets:\n",
    "        idx = (model, target, interaction)\n",
    "        print(idx)\n",
    "        with open('shap_values/'+rdir+'-'.join([str(i) for i in idx])+'.pkl','rb') as f:\n",
    "            results = pickle.load(f)\n",
    "        selected, misclassified =  select(results['y_true'], results['y_pred'], n_samples)\n",
    "        ax1, ax2 = make_shap_plots(model, target, \n",
    "                        results['shap_values'], \n",
    "                        results['expected_value'], \n",
    "                        selected,\n",
    "                        misclassified,\n",
    "                        results['features'], \n",
    "                        results['feature_names'],\n",
    "                        n_features=n_features,\n",
    "                        interactions=interaction,\n",
    "                        axes=axes[i],\n",
    "                        axes_labels = ['A','B'] if i==0 else ['C','D'])\n",
    "    ax1.set_title('LR L1 model of Resistant HTN' if i == 0 else 'FEAT model of Resistant HTN')\n",
    "    ax2.set_title('Example Decisions')\n",
    "    i+=1\n",
    "fig.set_size_inches((12,12))\n",
    "fig.suptitle('')\n",
    "fig.tight_layout()\n",
    "\n",
    "for filetype in ['.pdf','.png','.svg']:\n",
    "    plt.savefig('figs/'+rdir+'/'+'shap_combined_LRL1_FEAT'+filetype, dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make combined logistic regression / feat plot with interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          'LogisticRegression_L1',\n",
    "          'Feat_reconstruct_linear'\n",
    "         ]\n",
    "# models = ['Feat_reconstruct']\n",
    "targets = ['ResHtndx']\n",
    "\n",
    "n_samples = 20\n",
    "interactions=True\n",
    "fig, axes = plt.subplots(2,2, figsize=(12,12))\n",
    "print('axes shape:',axes.shape)\n",
    "i=0\n",
    "for model in models:\n",
    "    n_features = 20 if 'Feat' not in model else 6\n",
    "#     interaction = model != 'Feat_reconstruct_kernel'\n",
    "    interaction = True\n",
    "    for target in targets:\n",
    "        idx = (model, target, interaction)\n",
    "        print(idx)\n",
    "        with open('shap_values/'+rdir+'-'.join([str(i) for i in idx])+'.pkl','rb') as f:\n",
    "            results = pickle.load(f)\n",
    "        selected, misclassified =  select(results['y_true'], results['y_pred'], n_samples)\n",
    "        ax1, ax2 = make_shap_plots(model, target, \n",
    "                        results['shap_values'], \n",
    "                        results['expected_value'], \n",
    "                        selected,\n",
    "                        misclassified,\n",
    "                        results['features'], \n",
    "                        results['feature_names'],\n",
    "                        n_features=n_features,\n",
    "                        interactions=interaction,\n",
    "                        axes=axes[i],\n",
    "                        axes_labels = ['A','B'] if i==0 else ['C','D'])\n",
    "    ax1.set_title('LR L1 model of Resistant HTN' if i == 0 else 'FEAT model of Resistant HTN')\n",
    "    ax2.set_title('Example Decisions')\n",
    "    i+=1\n",
    "fig.set_size_inches((12,12))\n",
    "fig.suptitle('')\n",
    "fig.tight_layout()\n",
    "\n",
    "for filetype in ['.pdf','.png','.svg']:\n",
    "    plt.savefig('figs/'+rdir+'/'+'shap_combined_LRL1_FEAT_interactions'+filetype, dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab missing keys\n",
    "models = [\n",
    "          'LogisticRegression_L1',\n",
    "          'Feat_reconstruct_linear',\n",
    "          'Feat_reconstruct_kernel',\n",
    "          'RandomForest'\n",
    "         ]\n",
    "for model in models:\n",
    "    n_features = 20 if 'Feat' not in model else 6\n",
    "#     interaction = model != 'Feat_reconstruct_kernel'\n",
    "    interaction = False\n",
    "    for target in targets:\n",
    "        idx = (model, target, interaction)\n",
    "        print(idx)\n",
    "        with open('shap_values/'+rdir+'-'.join([str(i) for i in idx])+'.pkl','rb') as f:\n",
    "            results = pickle.load(f)\n",
    "        shap_values = results['shap_values']\n",
    "        mean_abs_sv = np.mean(np.abs(shap_values),axis=0)\n",
    "        sv_order = np.argsort(mean_abs_sv)[::-1]\n",
    "        feature_names = np.array(results['feature_names'])[sv_order[:n_features]]\n",
    "        \n",
    "        nice_feature_names = [' > '.join([feature_nice[fn.split('>')[0]]]+fn.split('>')[1:]) \n",
    "                            for fn in feature_names]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
